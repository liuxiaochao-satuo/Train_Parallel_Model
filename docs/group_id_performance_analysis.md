# æŒ‰group_idåˆ†æå®éªŒç»“æœæŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•åˆ†ææ¶ˆèå®éªŒç»“æœï¼Œç‰¹åˆ«å…³æ³¨**group_id=1ï¼ˆè¿åŠ¨å‘˜ï¼‰**çš„è¯†åˆ«ç²¾åº¦å˜åŒ–ã€‚

## è®­ç»ƒè¿‡ç¨‹ä¸­äº§ç”Ÿçš„æŒ‡æ ‡

### 1. æ•´ä½“æ€§èƒ½æŒ‡æ ‡ï¼ˆCocoMetricè‡ªåŠ¨è®¡ç®—ï¼‰

è®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹ä¸­ï¼Œ`CocoMetric` ä¼šè‡ªåŠ¨è®¡ç®—å¹¶è®°å½•ä»¥ä¸‹æŒ‡æ ‡ï¼š

**éªŒè¯é›†æŒ‡æ ‡ï¼ˆæ¯ä¸ªval_intervalè®°å½•ä¸€æ¬¡ï¼‰ï¼š**
- `val/coco/AP` - å¹³å‡ç²¾åº¦ï¼ˆä¸»æŒ‡æ ‡ï¼ŒåŸºäºOKSï¼‰
- `val/coco/AP50` - OKSé˜ˆå€¼0.5æ—¶çš„AP
- `val/coco/AP75` - OKSé˜ˆå€¼0.75æ—¶çš„AP
- `val/coco/APm` - ä¸­ç­‰å°ºå¯¸ç›®æ ‡çš„AP
- `val/coco/APl` - å¤§å°ºå¯¸ç›®æ ‡çš„AP
- `val/coco/AR` - å¹³å‡å¬å›ç‡
- `val/coco/AR50`, `AR75`, `ARm`, `ARl` - å¯¹åº”çš„å¬å›ç‡æŒ‡æ ‡

**è®­ç»ƒæŒ‡æ ‡ï¼š**
- `train/loss` - è®­ç»ƒæŸå¤±
- `train/loss/heatmap` - çƒ­å›¾æŸå¤±
- `train/loss/displacement` - ä½ç§»æŸå¤±
- `lr` - å­¦ä¹ ç‡

è¿™äº›æŒ‡æ ‡ä¿å­˜åœ¨ï¼š
- `work_dirs/.../vis_data/scalars.json` - JSONæ ¼å¼
- `work_dirs/.../vis_data/tf_event` - TensorBoardæ ¼å¼

### 2. é¢„æµ‹ç»“æœæ–‡ä»¶

éªŒè¯æˆ–æµ‹è¯•å®Œæˆåï¼Œ`CocoMetric` ä¼šä¿å­˜é¢„æµ‹ç»“æœåˆ°ï¼š
- `work_dirs/.../predictions/results.keypoints.json` - COCOæ ¼å¼çš„é¢„æµ‹ç»“æœ

è¿™ä¸ªæ–‡ä»¶åŒ…å«æ‰€æœ‰å›¾åƒçš„é¢„æµ‹å…³é”®ç‚¹ï¼Œç”¨äºåç»­çš„è¯¦ç»†åˆ†æã€‚

## å¦‚ä½•åˆ†ægroup_id=1ï¼ˆè¿åŠ¨å‘˜ï¼‰çš„ç²¾åº¦å˜åŒ–

### æ–¹æ³•1ï¼šä½¿ç”¨åˆ†æè„šæœ¬ï¼ˆæ¨èï¼‰

è¿è¡ŒæŒ‰group_idåˆ†æè„šæœ¬ï¼š

```bash
# ä»work_dirè‡ªåŠ¨æŸ¥æ‰¾é¢„æµ‹ç»“æœ
python tools/evaluate_by_group_id.py \
    --ann-file data/coco_parallel/annotations_id/person_keypoints_val_parallel.json \
    --work-dirs work_dirs/ablation_experiments/loss_weight_only \
                work_dirs/ablation_experiments/weighted_sampling_only \
                work_dirs/ablation_experiments/combined \
    --experiment-names "Loss Weight Only" "Weighted Sampling Only" "Combined" \
    --group-ids 1 2 3 4 \
    --output results/group_id_analysis.json
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
================================================================================
ğŸ¯ é‡ç‚¹åˆ†æï¼šgroup_id=1ï¼ˆè¿åŠ¨å‘˜ï¼‰
================================================================================

å®éªŒåç§°                        AP        AP50       AP75         AR
--------------------------------------------------------------------------------
Loss Weight Only            0.7234    0.8567    0.7891    0.8123
Weighted Sampling Only      0.7312    0.8612    0.7956    0.8198
Combined                    0.7456    0.8723    0.8089    0.8345

ç›¸å¯¹äºç¬¬ä¸€ä¸ªå®éªŒçš„æ”¹è¿›ï¼ˆgroup_id=1ï¼Œè¿åŠ¨å‘˜ï¼‰:
  Weighted Sampling Only     AP: 0.7312 (â†‘0.0078, â†‘1.08%)
  Combined                   AP: 0.7456 (â†‘0.0222, â†‘3.07%)
```

### æ–¹æ³•2ï¼šæ‰‹åŠ¨åˆ†æé¢„æµ‹ç»“æœ

å¦‚æœé¢„æµ‹æ–‡ä»¶å·²ç”Ÿæˆï¼Œå¯ä»¥æ‰‹åŠ¨åˆ†æï¼š

```python
import json
from xtcocotools.coco import COCO
from xtcocotools.cocoeval import COCOeval

# åŠ è½½æ ‡æ³¨å’Œé¢„æµ‹
coco_gt = COCO('data/coco_parallel/annotations_id/person_keypoints_val_parallel.json')
coco_dt = coco_gt.loadRes('work_dirs/exp/predictions/results.keypoints.json')

# è·å–group_id=1çš„annotation IDs
group_1_ann_ids = [
    ann_id for ann_id, ann in coco_gt.anns.items()
    if ann.get('group_id') == 1
]

# åˆ›å»ºè¿‡æ»¤åçš„è¯„ä¼°ï¼ˆéœ€è¦è‡ªå®šä¹‰å®ç°ï¼‰
# ... ä½¿ç”¨evaluate_by_group_id.pyè„šæœ¬æ›´æ–¹ä¾¿
```

## å®Œæ•´åˆ†ææµç¨‹

### æ­¥éª¤1ï¼šè®­ç»ƒå®Œæˆåï¼Œç¡®ä¿æœ‰é¢„æµ‹ç»“æœ

å¦‚æœéªŒè¯æ—¶æ²¡æœ‰ç”Ÿæˆé¢„æµ‹æ–‡ä»¶ï¼Œå¯ä»¥è¿è¡Œæµ‹è¯•ï¼š

```bash
python tools/test.py \
    configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel_ablation_loss_weight.py \
    work_dirs/ablation_experiments/loss_weight_only/checkpoints/best.pth \
    --out work_dirs/ablation_experiments/loss_weight_only/predictions/results.json
```

### æ­¥éª¤2ï¼šè¿è¡Œgroup_idåˆ†æ

```bash
python tools/evaluate_by_group_id.py \
    --ann-file data/coco_parallel/annotations_id/person_keypoints_val_parallel.json \
    --work-dirs work_dirs/ablation_experiments/loss_weight_only \
                work_dirs/ablation_experiments/weighted_sampling_only \
                work_dirs/ablation_experiments/combined \
    --experiment-names "Loss Weight" "Weighted Sampling" "Combined" \
    --group-ids 1 \
    --output results/athlete_analysis.json
```

### æ­¥éª¤3ï¼šæŸ¥çœ‹æ•´ä½“æ€§èƒ½å¯¹æ¯”

ä½¿ç”¨ä¹‹å‰çš„åˆ†æè„šæœ¬æŸ¥çœ‹æ•´ä½“æ€§èƒ½ï¼š

```bash
python tools/analyze_ablation_results.py \
    --base-dir work_dirs/ablation_experiments \
    --experiments loss_weight_only weighted_sampling_only combined \
    --names "Loss Weight" "Weighted Sampling" "Combined"
```

### æ­¥éª¤4ï¼šç»¼åˆå¯¹æ¯”

å¯¹æ¯”ä¸¤ä¸ªç»“æœï¼š
- **æ•´ä½“AP**ï¼šæ‰€æœ‰æ ·æœ¬çš„å¹³å‡æ€§èƒ½
- **group_id=1çš„AP**ï¼šè¿åŠ¨å‘˜æ ·æœ¬çš„æ€§èƒ½

ç†æƒ³æƒ…å†µä¸‹ï¼š
- æ•´ä½“APåº”è¯¥ä¿æŒæˆ–æå‡
- group_id=1çš„APåº”è¯¥æœ‰æ˜æ˜¾æå‡

## ç»“æœè§£è¯»

### æˆåŠŸæ¡ˆä¾‹

```
æ•´ä½“APå¯¹æ¯”ï¼š
  Loss Weight:     0.7123
  Weighted Sampling: 0.7145 (+0.22%)
  Combined:        0.7189 (+0.66%)

group_id=1ï¼ˆè¿åŠ¨å‘˜ï¼‰APå¯¹æ¯”ï¼š
  Loss Weight:     0.7034
  Weighted Sampling: 0.7212 (+2.53%)  â† æ˜æ˜¾æå‡
  Combined:        0.7356 (+4.58%)  â† æ˜¾è‘—æå‡
```

**è§£è¯»ï¼š**
- âœ… æ•´ä½“æ€§èƒ½ç•¥æœ‰æå‡
- âœ… group_id=1çš„æ€§èƒ½æ˜¾è‘—æå‡ï¼ˆ+4.58%ï¼‰
- âœ… ç­–ç•¥æœ‰æ•ˆ

### éœ€è¦æ³¨æ„çš„æƒ…å†µ

```
æ•´ä½“APå¯¹æ¯”ï¼š
  Loss Weight:     0.7123
  Combined:        0.7089 (-0.34%)  â† æ•´ä½“ç•¥æœ‰ä¸‹é™

group_id=1ï¼ˆè¿åŠ¨å‘˜ï¼‰APå¯¹æ¯”ï¼š
  Loss Weight:     0.7034
  Combined:        0.7456 (+6.00%)  â† æ˜¾è‘—æå‡
```

**è§£è¯»ï¼š**
- âš ï¸ æ•´ä½“æ€§èƒ½ç•¥æœ‰ä¸‹é™ï¼ˆå¯èƒ½è¿‡åº¦ä¼˜åŒ–group_id=1ï¼‰
- âœ… group_id=1æ€§èƒ½æ˜¾è‘—æå‡
- ğŸ’¡ å»ºè®®ï¼šé™ä½æƒé‡ï¼ˆå¦‚ä»2.0é™åˆ°1.5ï¼‰æˆ–è°ƒæ•´ç­–ç•¥

## å¯è§†åŒ–ç»“æœ

### ä½¿ç”¨TensorBoard

```bash
tensorboard --logdir work_dirs/ablation_experiments
```

åœ¨TensorBoardä¸­å¯¹æ¯”ï¼š
- `val/coco/AP` æ›²çº¿ï¼ˆæ•´ä½“æ€§èƒ½ï¼‰
- è®­ç»ƒæŸå¤±æ›²çº¿ï¼ˆè§‚å¯Ÿæ˜¯å¦è¿‡æ‹Ÿåˆï¼‰

### åˆ›å»ºå¯¹æ¯”å›¾è¡¨

å¯ä»¥ç¼–å†™è„šæœ¬ä» `results/group_id_analysis.json` ç”Ÿæˆå¯¹æ¯”å›¾è¡¨ï¼š

```python
import json
import matplotlib.pyplot as plt

with open('results/group_id_analysis.json') as f:
    results = json.load(f)

# æå–group_id=1çš„AP
experiments = list(results.keys())
ap_values = [results[exp][1]['AP'] for exp in experiments]

plt.bar(experiments, ap_values)
plt.title('Group ID=1 (Athletes) AP Comparison')
plt.ylabel('AP')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('results/athlete_ap_comparison.png')
```

## å…³é”®æŒ‡æ ‡è¯´æ˜

### AP (Average Precision)
- **æœ€é‡è¦**ï¼šç»¼åˆè¯„ä¼°æŒ‡æ ‡ï¼ŒåŸºäºOKSè®¡ç®—
- **èŒƒå›´**ï¼š0-1ï¼Œè¶Šé«˜è¶Šå¥½
- **å«ä¹‰**ï¼šåœ¨æ‰€æœ‰OKSé˜ˆå€¼ä¸‹çš„å¹³å‡ç²¾åº¦

### AP50 / AP75
- **å«ä¹‰**ï¼šOKSé˜ˆå€¼åˆ†åˆ«ä¸º0.5å’Œ0.75æ—¶çš„ç²¾åº¦
- **ç”¨é€”**ï¼šè¯„ä¼°ä¸åŒä¸¥æ ¼ç¨‹åº¦ä¸‹çš„æ€§èƒ½

### AR (Average Recall)
- **å«ä¹‰**ï¼šå¹³å‡å¬å›ç‡
- **ç”¨é€”**ï¼šè¯„ä¼°æ¨¡å‹èƒ½æ‰¾åˆ°å¤šå°‘æ­£ç¡®çš„å…³é”®ç‚¹

## å¸¸è§é—®é¢˜

### Q: é¢„æµ‹æ–‡ä»¶åœ¨å“ªé‡Œï¼Ÿ

A: é€šå¸¸åœ¨ä»¥ä¸‹ä½ç½®ï¼š
- `work_dirs/.../predictions/results.keypoints.json`
- `work_dirs/.../*.keypoints.json`

å¦‚æœæ‰¾ä¸åˆ°ï¼Œéœ€è¦å…ˆè¿è¡Œæµ‹è¯•ç”Ÿæˆé¢„æµ‹ç»“æœã€‚

### Q: å¦‚ä½•ç¡®ä¿é¢„æµ‹æ–‡ä»¶åŒ…å«æ‰€æœ‰éªŒè¯æ ·æœ¬ï¼Ÿ

A: è¿è¡Œå®Œæ•´çš„éªŒè¯æˆ–æµ‹è¯•ï¼š
```bash
python tools/test.py config.py checkpoint.pth
```

### Q: group_id=1çš„APæå‡äº†ï¼Œä½†æ•´ä½“APä¸‹é™äº†æ€ä¹ˆåŠï¼Ÿ

A: å¯èƒ½è¿‡åº¦ä¼˜åŒ–äº†group_id=1ï¼Œå»ºè®®ï¼š
1. é™ä½æƒé‡ï¼ˆå¦‚ä»2.0é™åˆ°1.5ï¼‰
2. ä½¿ç”¨è¯¾ç¨‹å­¦ä¹ ï¼ˆé€æ¸å¢åŠ æƒé‡ï¼‰
3. æ£€æŸ¥æ˜¯å¦æœ‰è¿‡æ‹Ÿåˆ

## æ€»ç»“

é€šè¿‡æŒ‰group_idåˆ†æï¼Œæ‚¨å¯ä»¥ï¼š
1. âœ… æ˜ç¡®çŸ¥é“group_id=1ï¼ˆè¿åŠ¨å‘˜ï¼‰çš„ç²¾åº¦å˜åŒ–
2. âœ… å¯¹æ¯”ä¸åŒç­–ç•¥å¯¹è¿åŠ¨å‘˜è¯†åˆ«çš„æ•ˆæœ
3. âœ… å¹³è¡¡æ•´ä½“æ€§èƒ½å’Œç‰¹å®šgroup_idçš„æ€§èƒ½
4. âœ… åšå‡ºæ•°æ®é©±åŠ¨çš„å†³ç­–

